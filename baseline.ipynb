{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afda5049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dataloader import loader\n",
    "import warnings\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa7d9fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "class TinyEEGCNN(nn.Module):\n",
    "    def __init__(self, in_ch=41):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(in_ch, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=5, stride=2, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),  # -> [B, 128, 1]\n",
    "        )\n",
    "        self.fc = nn.Linear(128, 1)  # binary logit\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.net(x).squeeze(-1)  # [B, 128]\n",
    "        return self.fc(h).squeeze(-1)  # [B]\n",
    "\n",
    "\n",
    "dataloader = DataLoader(\n",
    "        ds,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=False,\n",
    "        collate_fn=collate_xy\n",
    "    )\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TinyEEGCNN().to(device)\n",
    "print(\"Model device:\", next(model.parameters()).device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "218eecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/tinycnn\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "071174ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | loss=0.5713 | acc=0.725\n",
      "Epoch 02 | loss=0.5491 | acc=0.732\n",
      "Epoch 03 | loss=0.5245 | acc=0.750\n",
      "Epoch 04 | loss=0.5086 | acc=0.766\n",
      "Epoch 05 | loss=0.4918 | acc=0.779\n",
      "Epoch 06 | loss=0.4768 | acc=0.787\n",
      "Epoch 07 | loss=0.4602 | acc=0.799\n",
      "Epoch 08 | loss=0.4474 | acc=0.805\n",
      "Epoch 09 | loss=0.4378 | acc=0.810\n",
      "Epoch 10 | loss=0.4281 | acc=0.814\n",
      "Done. Run: tensorboard --logdir runs\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "step = 0\n",
    "for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        for batch in dataloader:\n",
    "            x = batch[\"x\"].to(device, non_blocking=True).float()\n",
    "            y = batch[\"y\"].to(device, non_blocking=True).float()\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            total += x.size(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "                correct += (preds == y).sum().item()\n",
    "\n",
    "            writer.add_scalar(\"train/loss_step\", loss.item(), step)\n",
    "            step += 1\n",
    "\n",
    "        epoch_loss = total_loss / max(total, 1)\n",
    "        epoch_acc = correct / max(total, 1)\n",
    "\n",
    "        writer.add_scalar(\"train/loss_epoch\", epoch_loss, epoch)\n",
    "        writer.add_scalar(\"train/acc_epoch\", epoch_acc, epoch)\n",
    "        print(f\"Epoch {epoch:02d} | loss={epoch_loss:.4f} | acc={epoch_acc:.3f}\")\n",
    "\n",
    "writer.close()\n",
    "print(\"Done. Run: tensorboard --logdir runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f77d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: True\n",
      "gpu: NVIDIA GeForce RTX 3060\n",
      "model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"gpu:\", torch.cuda.get_device_name(0))\n",
    "print(\"model device:\", next(model.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaf14635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps per epoch (len(loader)): 4176\n",
      "avg sec/batch: 0.05610127925872803\n",
      "estimated epoch time: 234.27894218444825 sec = 3.904649036407471 min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "print(\"steps per epoch (len(loader)):\", len(dataloader))\n",
    "\n",
    "# warmup a few batches (important)\n",
    "for i, batch in enumerate(dataloader):\n",
    "    if i == 10:\n",
    "        break\n",
    "\n",
    "torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "\n",
    "t0 = time.time()\n",
    "num_batches = 100\n",
    "\n",
    "for i, batch in enumerate(dataloader):\n",
    "    # move to GPU like in training (to measure realistically)\n",
    "    x = batch[\"x\"].to(device, non_blocking=True)\n",
    "    y = batch[\"y\"].to(device, non_blocking=True)\n",
    "\n",
    "    # tiny forward to include GPU compute (optional)\n",
    "    with torch.no_grad():\n",
    "        _ = model(x)\n",
    "\n",
    "    if i + 1 >= num_batches:\n",
    "        break\n",
    "\n",
    "torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "t1 = time.time()\n",
    "\n",
    "avg = (t1 - t0) / num_batches\n",
    "print(\"avg sec/batch:\", avg)\n",
    "\n",
    "epoch_est = avg * len(dataloader)\n",
    "print(\"estimated epoch time:\", epoch_est, \"sec =\", epoch_est/60, \"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8527cd53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
